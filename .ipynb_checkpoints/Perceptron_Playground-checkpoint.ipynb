{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "\n",
    "# setosa and versicolor\n",
    "y = df.iloc[0:25, 4].values\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "\n",
    "# sepal length and petal length\n",
    "X = df.iloc[0:100, [0,2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self, eta=0.01, epochs=50):\n",
    "        # eta is the \"learning rate\n",
    "        # epochs are the max number of times to iterate over the date\n",
    "            # this is critical, if convergence will not occur\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # We begin by creating the weight vector,\n",
    "        # values are intialized to zero,\n",
    "        # There are one more dimensions than the number of columns in the matrix\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        # we create an empty list of errors\n",
    "        self.errors_ = []\n",
    "        print(self.w_) # I print the weight vector to confirm its contents\n",
    "    \n",
    "        # loop for as many times as the value of the max. epochs variable\n",
    "        for e in range(self.epochs):\n",
    "            print(\"\\nEpoch \", str(e+1), \"\\n\\n\")\n",
    "            # a local value to store the number of erros in this epoch\n",
    "            errors = 0\n",
    "            # for each vector-class pair in the training set...\n",
    "            # xi is the instance vector, sepal and pedal length in this case\n",
    "            # target is the true class label\n",
    "            for xi, target in zip(X, y):\n",
    "                # Multiply the learning rate (self.eta),\n",
    "                    # by the true value (target) minus the predicted value\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                # multiply the update by the values of the sample vector\n",
    "                self.w_[1:] +=  update * xi\n",
    "                print(\"w_[1:]\",self.w_[1:])\n",
    "                push the \n",
    "                self.w_[0] +=  update\n",
    "                print(\"w_[0]\",self.w_[0])\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        # here we are taking the dot product of m number of features,\n",
    "            # and the corresponding weight vector for the data set.\n",
    "        net_input_result = np.dot(X, self.w_[1:]) + self.w_[0] # self.w_[0] is the bias\n",
    "        print(\"Dot product:\", net_input_result)\n",
    "        return net_input_result\n",
    "\n",
    "    def predict(self, X):\n",
    "        # it is important to note that X here IS NOT the sample matrix.\n",
    "            # it is a specific sample!.. argument (xi) from the update = line\n",
    "        # np.where works like the unit step function.\n",
    "            # If positive, 1. If negative, -1. If 0, 0.\n",
    "        predict_result = np.where(self.net_input(X) >= 0.0, 1, -1)\n",
    "        print(\"Prediction: \", predict_result)\n",
    "        return predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppn = Perceptron(epochs=10, eta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  1.4],\n",
       "       [ 4.9,  1.4],\n",
       "       [ 4.7,  1.3],\n",
       "       [ 4.6,  1.5],\n",
       "       [ 5. ,  1.4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ppn.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vector = np.array([1,2,3])\n",
    "targets       = np.array([-1,-1,0,1,1])\n",
    "w_vector      = np.array([0,0,0])\n",
    "predictions   = np.array([1,1,0,-1,-1])\n",
    "eta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  *  ( -1  -  1 )  =  -2\n",
      "1  *  ( -1  -  1 )  =  -2\n",
      "1  *  ( 0  -  0 )  =  0\n",
      "1  *  ( 1  -  -1 )  =  2\n",
      "1  *  ( 1  -  -1 )  =  2\n"
     ]
    }
   ],
   "source": [
    "for p,t in zip(predictions,targets):\n",
    "    print(str(eta),\" * \", \"(\", str(t), \" - \", str(p),\")\", end=\" \")\n",
    "    update = eta * (t - p)\n",
    "    print(\" = \", update)\n",
    "    w_vector +=  update * sample_vector\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
